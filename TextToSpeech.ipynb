{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextToSpeech.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QgiRAgF1Dngh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrN2Ur80Ylxl"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrYGQgbfYpYG"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI7kMPVDq5hg"
      },
      "source": [
        "Google Text To Speech module: convert text into speech in several languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYjd-2ZuNtmx"
      },
      "source": [
        "!pip install gTTS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIYlNV-dry2P"
      },
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEA504SjrNnK"
      },
      "source": [
        "Tesseract allows to extract text from an image and convert it into a string.\n",
        "\n",
        "To install the library, first install _tesseract-ocr_ package and then _pytesseract_ one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_lLUzsPkx_B"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqJjGHFiYrRD"
      },
      "source": [
        "Now, import the libraries that will be necessary to use the module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRdS_XnlXYYo"
      },
      "source": [
        "try:\n",
        "  from PIL import Image\n",
        "except ImportError:\n",
        "  import Image\n",
        "import cv2\n",
        "import pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f93E9fvBr0ix"
      },
      "source": [
        "Check where the .exe file is stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UB8_yljfJGK"
      },
      "source": [
        "!which tesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzaBNKsqr6Aw"
      },
      "source": [
        "Establish the environment to run the .exe properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNxF4Ibnle3t"
      },
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sloDZjcYwBT"
      },
      "source": [
        "# Google Text To Speech "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqwR_99VY3xH"
      },
      "source": [
        "Benchmark of testings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFkPnvkBW5bq"
      },
      "source": [
        "text = \"Hello! My name is Hugo\"\n",
        "tts = gTTS(text)\n",
        "tts.save(\"hi.wav\")\n",
        "sound_file = 'hi.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0AvfEXPl8Y_"
      },
      "source": [
        "# Text recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI2Kb1n7sAbD"
      },
      "source": [
        "Check the available languages supported by tesseract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thl2FrAwnnxq"
      },
      "source": [
        "pytesseract.get_languages()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvXXS23ysEjY"
      },
      "source": [
        "Load an image from Drive using cv2 library. By default, cv2 read expect images in BGR format, so we need to convert them into RGB format, expected by the tesseract package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNRWAf2HZkWj"
      },
      "source": [
        "image_bgr = cv2.imread(r'/content/drive/MyDrive/Colab Notebooks/Projects/NLP/Resources/photo.jpeg')\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUR7uqh1KD1"
      },
      "source": [
        "Recognize the words in image and save them into an auxiliary string variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBjLfUQn1HQE"
      },
      "source": [
        "text = pytesseract.image_to_string(image_rgb, lang = 'eng', config = '-psm 1')\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oUA7LYq1XfW"
      },
      "source": [
        "Convert text into speech using gTTS. Then, save it into an auxiliary .wav file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wflc2chK1WwR"
      },
      "source": [
        "tts = gTTS(text, lang = 'es-us')\n",
        "tts.save(\"hi.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yp95yvk1hMM"
      },
      "source": [
        "Reproduce the audio file using Audio package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsTM7vME1mS6"
      },
      "source": [
        "sound_file = 'hi.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgiRAgF1Dngh"
      },
      "source": [
        "## Convert pdf into images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZCJUXDLG8wN"
      },
      "source": [
        "To convert pdf file into images, we will need two libraries: _poppler_ and _pdf2image_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugok15JWHXZB"
      },
      "source": [
        "!apt-get install poppler-utils &> /dev/null\n",
        "!pip install pdf2image &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7c_etrcHcVu"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from IPython.display import display, Image\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKoGgZFHDrn"
      },
      "source": [
        "### Upload pdf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ1Dsr0UHP34"
      },
      "source": [
        "print(\"\\nPlease upload PDF files.\")\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print(\"\")\n",
        "    if(fn.lower()[-4:] != \".pdf\"):\n",
        "        print(f\"{fn} is not PDF file!\")\n",
        "        continue\n",
        "    images = convert_from_bytes(uploaded[fn], size=800)\n",
        "    with zipfile.ZipFile(f\"{fn[:-4]}.zip\", \"w\", compression=zipfile.ZIP_DEFLATED) as new_zip:\n",
        "        for i, page in enumerate(images):\n",
        "            name = f\"{fn[:-4]}_{i+1}.png\"\n",
        "            page.save(name, \"PNG\")\n",
        "            new_zip.write(name, arcname=name)\n",
        "            print(f\"{fn} p.{i+1} > {name}\")\n",
        "    print(\"Convert completed.\\nThe download will start...\")\n",
        "    files.download(f\"{fn[:-4]}.zip\")\n",
        "print(\"\\nFinished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnJD8DCFHjr6"
      },
      "source": [
        "### Use pdf from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5z0d_mF33I"
      },
      "source": [
        "pdf_path = '/content/drive/MyDrive/Colab Notebooks/Projects/NLP/Resources/prueba.pdf'\n",
        "pdf_image = convert_from_path(pdf_path)\n",
        "for i, page in enumerate(pdf_image):\n",
        "  name = f\"pdf_{i+1}.png\"\n",
        "  page.save(name, \"PNG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyE4NZhLJuog"
      },
      "source": [
        "path_to_pdf_image = '/content/pdf_1.png'\n",
        "pdf_text = pytesseract.image_to_string(path_to_pdf_image, lang = 'eng', config = '-psm 1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3A0bnvFIEHi"
      },
      "source": [
        "`pdf_image` is a PIL image. We need to convert it into cv2 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r98XhKizHrIP"
      },
      "source": [
        "print(pdf_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sud6F14FeYnn"
      },
      "source": [
        "Finally, we convert the text into speech using gTTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6C1iT_NefdZ"
      },
      "source": [
        "tts = gTTS(pdf_text, lang = 'es-us')\n",
        "tts.save(\"pdf.wav\")\n",
        "sound_file = 'pdf.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9egl0bzLe7XM"
      },
      "source": [
        "## From an image take with the webcam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TId5Yjp1fk32"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJrqPKM5fmwC"
      },
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "import numpy as np\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UwTNH_gfHOm"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrZA92JbfBqZ"
      },
      "source": [
        "# Function to convert JavaScript objects into OpenCV images\n",
        "def js_to_image(js_reply):\n",
        "\n",
        "  # Decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "\n",
        "  # Convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype = np.uint8)\n",
        "\n",
        "  # Decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags = 1)\n",
        "\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQTitjUHfNPm"
      },
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "\n",
        "  # put data in opencv format\n",
        "  img = js_to_image(data)\n",
        "\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "  \n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51SeWUeXfXIT"
      },
      "source": [
        "### Take a picture with the webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6dwht3tfWd5"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuNjce1If6Mh"
      },
      "source": [
        "### Text recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjUyB037f52r"
      },
      "source": [
        "photo_bgr = cv2.imread(r'/content/photo.jpg')\n",
        "photo_rgb = cv2.cvtColor(photo_bgr, cv2.COLOR_BGR2RGB)\n",
        "text = pytesseract.image_to_string(photo_rgb, lang = 'eng', config = '-psm 1')\n",
        "text = text.replace('-','')\n",
        "text = text.replace('|','')\n",
        "text = text.replace('_','')\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch51OxekgPEi"
      },
      "source": [
        "tts = gTTS(text, lang = 'es-us')\n",
        "tts.save(\"hi.wav\")\n",
        "sound_file = 'hi.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}